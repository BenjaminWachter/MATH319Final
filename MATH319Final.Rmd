---
title: "MATH319Final"
output: html_notebook
---

```{r}
library(reticulate)
```

Importing python code
```{r}
auto_diff <- reticulate::import("forward_auto_diff")
```

Defining parameters
```{r}
x0 <- c(1.2, 1.2)
c1 <- 0.4
rho <- 0.8
tol <- 0.000001
iter <- 500

```

Creating functions
```{r}
# rosenbrock function
rosenbrock <- function(x1, x2) {
  out <- (x2-x1^2)^2 + (1-x1)^2
  return(out)
}

# rosenbrock function
rosenbrock2 <- function(x1, x2) {
  out <- cos(x1)*sin(x2)+x1*x1
  return(out)
}
```

Steepest descent
```{r}
# make a contour plot
x1 <- seq(0.9, 1.3, length.out=100)
x2 <- x1
z <- outer(x1, x2,FUN=rosenbrock)
plot_contour <- contour(x1, x2, z, nlevels=50, 
                        main="Contour Plot of Rosenbrock Function - Steepest Descent")
  
# steepest descent function
steepest_descent <- function(func, x0) {
  # plot initial point x0
  points(x0[1], x0[2], col="blue", pch=16)
  
  # initialize variables 
  xk <- x0
  ####### computing gradient from auto_diff ########
  var1 <- auto_diff$Var(xk[1], 0)
  var2 <- auto_diff$Var(xk[2], 0)
  grad <- auto_diff$compute_grad(c(var1, var2))
  #################################################
  norm_g <- norm(c(grad[1], grad[2]), type="2")
  count <- 0
  
  # algorithm logic
  while(count < iter && norm_g > tol) {
    a <- 1
    pk <- -grad
    # initialize step length variables
    x_ap <- xk + a*pk
    wolfe = func(x_ap[1], x_ap[2]) < 
            (func(xk[1], xk[2]) + c1*a*t(grad)%*%pk) 
    # compute step length based on first Wolfe condition
    while (!wolfe) {
      # update step length
      a <- rho*a
      # update wolfe condition
      x_ap <- xk + a*pk
      wolfe = func(x_ap[1], x_ap[2]) < 
              (func(xk[1], xk[2]) + c1*a*t(grad)%*%pk)
    }
    # update iterate and norm
    xk_o <- xk
    xk <- xk + a*pk
    ####### computing gradient from auto_diff ########
    var1 <- auto_diff$Var(xk[1], 0)
    var2 <- auto_diff$Var(xk[2], 0)
    grad <- auto_diff$compute_grad(c(var1, var2))
    #################################################
    norm_g <- norm(c(grad[1], grad[2]), type="2")
    count <-  count + 1
    # plot iterate
    points(xk[1], xk[2])
    segments(xk_o[1], xk_o[2], xk[1], xk[2])
  }
  
  cat("Iterations: ", count, "\n")
  cat("Optimal value: ", xk)
}

steepest_descent(rosenbrock, x0)
# plot optimal solution
points(1,1, col="green", pch=16)
```

